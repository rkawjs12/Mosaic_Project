{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from PIL import Image, ImageFilter\n",
    "from matplotlib import pyplot\n",
    "from numpy import savez_compressed\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import mtcnn\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "\n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(160, 160)):\n",
    "\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = asarray(image)\n",
    "\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "\n",
    "    # extract the bounding box from the first face\n",
    "    face_list =[]\n",
    "    # face_array는 자른 얼굴을 저장할 list로, 크기는 (160,160,3)\n",
    "    coordinate_of_face_list =[]\n",
    "    # coordinate_of_face_list는 자른 얼굴이 가지는 좌표를 나타내는 list로, 크기는 (n,5)이며, n은 detection된 얼굴의 수를 의미한다. 값은 x1, y1, x2, y2, 모자이크 유무(mosaic)를 의미한다.\n",
    "    mosaic = 0\n",
    "\n",
    "    if results is None:\n",
    "        print(filename + \"this image doesn't have face\")\n",
    "        return filename + \"this image doesn't have face\"\n",
    "\n",
    "    else:\n",
    "        for i in range(len(results)):\n",
    "            x1, y1, width, height = results[i]['box']\n",
    "            # bug fix\n",
    "            x1, y1 = abs(x1), abs(y1)\n",
    "            x2, y2 = x1 + width, y1 + height\n",
    "            # extract the face\n",
    "            face = pixels[y1:y2, x1:x2]\n",
    "            # resize pixels to the model size\n",
    "            image = Image.fromarray(face)\n",
    "            image = image.resize(required_size)\n",
    "            face_list.append(asarray(image))\n",
    "            # face_list는 mtcnn을 통해 검출된 얼굴 array 형식으로 저장한 list이다. \n",
    "            coordinate_of_face_list.append([x1,y1,x2,y2,mosaic])\n",
    "\n",
    "        return  face_list, coordinate_of_face_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the face embedding for one face\n",
    "# 이 함수는 자른 얼굴을 face embedding 시켜주는 함수이다.\n",
    "\n",
    "def get_embedding(model, face_list):\n",
    "    # face_list는 자른 얼굴을 가진 list이다.\n",
    "    face_embedding_list = list()\n",
    "    #face_embedding_list는 자른 얼굴을 face_embedding 시킨 결과이다.\n",
    "\n",
    "    for i in range(len(face_list)):\n",
    "        # scale pixel values]\n",
    "        face_pixels = face_list[i].astype('float32')\n",
    "        # standardize pixel values across channels (global)\n",
    "        mean, std = face_pixels.mean(), face_pixels.std()\n",
    "        face_pixels = (face_pixels - mean) / std\n",
    "        # transform face into one sample\n",
    "        samples = expand_dims(face_pixels, axis=0)\n",
    "        # make prediction to get embedding\n",
    "        yhat = model.predict(samples)    \n",
    "        face_embedding_list.append(yhat[0])\n",
    "        face_embedding_list = asarray(face_embedding_list)\n",
    "\n",
    "    return face_embedding_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmPredict(face_embedding_list, SVM_file, in_encoder_file = \"in_encoder_SVM_Chaewon, Chaeyeon, Eunbi, Hitomi.sav\", out_encoder_file = \"out_encoder_SVM_Chaewon, Chaeyeon, Eunbi, Hitomi.sav\"):\n",
    "  # face_embedding_list는 잘린 얼굴을 face_embedding시켜 list에 저장한 것, coordinate_of_face_list는 자른 얼굴의 좌표, face_list는 내가 모자이크 안하고자 하는 얼굴,\n",
    "  SVM_loaded_model = pickle.load(open(SVM_file,'rb'))\n",
    "  in_encoder = pickle.load(open(in_encoder_file,'rb'))\n",
    "  out_encoder = pickle.load(open(out_encoder_file,'rb'))\n",
    "\n",
    "  SVM_predict_result = []\n",
    "  for i in range(len(face_embedding_list)):\n",
    "    #face_embedding_list = in_encoder.transform(face_embedding_list)\n",
    "    sample = expand_dims(face_embedding_list[i], axis = 0)\n",
    "\n",
    "    yhat_class = SVM_loaded_model.predict(sample)\n",
    "    yhat_face_name = out_encoder.inverse_transform([yhat_class])\n",
    "    yhat_prob = SVM_loaded_model.predict_proba(sample)*100\n",
    "    \n",
    "    class_index = yhat_class[0]\n",
    "    predict_names = out_encoder.inverse_transform(yhat_class)\n",
    "    class_probability = yhat_prob[0,class_index]\n",
    "    SVM_predict_result.append([predict_names, class_probability])  \n",
    "    #SVM_predict_result.append([yhat_face_name, yhat_prob])  \n",
    "    print(SVM_predict_result[i])\n",
    "  \n",
    "  return SVM_predict_result\n",
    "#SVM_predict_result에는 가장 확률에 해당하는 이름과 확률이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_SVM_out_encoder(dont_want_mosaic_facelist):\n",
    "    SVM_path = 'SVM/'\n",
    "    out_encoder_path = 'out_encoder/'\n",
    "\n",
    "    SVM_path_list = os.listdir(SVM_path)\n",
    "    out_encoder_list = os.listdir(out_encoder_path)\n",
    "\n",
    "    index_list_for_load_SVM = []\n",
    "    index_list_for_load_out_encoder = []\n",
    "\n",
    "    mod = sys.modules[__name__]\n",
    "\n",
    "    # dont_want_mosaic_facelist를 통해서 out_encoder, SVM을 load하는 과정\n",
    "    for dont_want_mosaic_face in dont_want_mosaic_facelist:\n",
    "        index_list_for_load_SVM.append(SVM_path_list.index(\"SVM_\" + dont_want_mosaic_face + \".pkl\"))\n",
    "        index_list_for_load_out_encoder.append(out_encoder_list.index(\"out_encoder_\" + dont_want_mosaic_face + \".pkl\"))\n",
    "\n",
    "    SVM_list = []\n",
    "    out_encoder_list = []\n",
    "\n",
    "    for index in index_list_for_load_SVM:\n",
    "        SVM_list.append(pickle.load(open(SVM_path + SVM_path_list[index],'rb')))\n",
    "\n",
    "    for index in index_list_for_load_out_encoder:\n",
    "        out_encoder_list.append(pickle.load(open(out_encoder_path + out_encoder_path_list[index],'rb')))\n",
    "        \n",
    "    return SVM_list, out_encoder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dont_want_mosaic_facelist = [\"ITZY Yuna\", \"ITZY Yeji\"]\n",
    "imagefile = \"ITZY_for_test.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_mosaic_function(imagefile , dont_want_mosaic_facelist):\n",
    "# filename는 이미지를 의미하고, dont_want_mosaic_facelist는 모자이크를 하지 말아야하는 사람들 list를 의미한다.\n",
    "    \n",
    "    SVM_path = 'SVM/'\n",
    "    out_encoder_path = 'out_encoder/'\n",
    "    \n",
    "    SVM_path_list = os.listdir(SVM_path)\n",
    "    out_encoder_path_list = os.listdir(out_encoder_path)\n",
    "    \n",
    "    index_list_for_load_SVM = []\n",
    "    index_list_for_load_out_encoder = []\n",
    "    \n",
    "    mod = sys.modules[__name__]\n",
    "    \n",
    "    # dont_want_mosaic_facelist를 통해서 out_encoder, SVM을 load하는 과정\n",
    "    for dont_want_mosaic_face in dont_want_mosaic_facelist:\n",
    "        index_list_for_load_SVM.append(SVM_path_list.index(\"SVM_\" + dont_want_mosaic_face + \".pkl\"))\n",
    "        index_list_for_load_out_encoder.append(out_encoder_path_list.index(\"out_encoder_\" + dont_want_mosaic_face + \".pkl\"))\n",
    "        \n",
    "        \n",
    "    SVM_list = []\n",
    "    out_encoder_list = []\n",
    "    \n",
    "    for index in index_list_for_load_SVM:\n",
    "        SVM_list.append(pickle.load(open(SVM_path + SVM_path_list[index],'rb')))\n",
    "    \n",
    "    for index in index_list_for_load_out_encoder:\n",
    "        out_encoder_list.append(pickle.load(open(out_encoder_path + out_encoder_path_list[index],'rb')))\n",
    "    \n",
    "    print(SVM_path_list[0])\n",
    "    print(SVM_path_list[4])\n",
    "    \n",
    "    print(index_list_for_load_SVM)\n",
    "    \n",
    "    print(out_encoder_path_list[4])\n",
    "    print(out_encoder_path_list[3])\n",
    "    print(index_list_for_load_out_encoder)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    face_list, coordinate_of_face_list = extract_face(filename, required_size=(160, 160))\n",
    "\n",
    "    model = load_model('facenet_keras.h5')\n",
    "    face_embedding_list = get_embedding(model,face_list)\n",
    "    SVM_predict_result = svmPredict(face_embedding_list,SVM_file)\n",
    "\n",
    "    threshold = 90\n",
    "\n",
    "    for i, result in enumerate(SVM_predict_result):\n",
    "        #print(result[0], result[1])\n",
    "        if (result[0] in mosaic_facelist) and (result[1] >= threshold):\n",
    "        coordinate_of_face_list[i][4] = 1\n",
    "        #print(coordinate_of_face_list[i][4])\n",
    "\n",
    "    image = Image.open(filename)\n",
    "    \n",
    "    for [x1,y1,x2,y2,mosaic] in coordinate_of_face_list:\n",
    "        if mosaic == 0:\n",
    "        cropped_image = image.crop((x1,y1,x2,y2))\n",
    "        blurred_image = cropped_image.filter(ImageFilter.GaussianBlur(radius = 10))\n",
    "        image.paste(blurred_image,(x1,y1,x2,y2))\n",
    "\n",
    "    image.show()\n",
    "    image.save('result_image3.jpg')\n",
    "    return image\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_ITZY Yeji.pkl\n",
      "SVM_ITZY Yuna.pkl\n",
      "[4, 0]\n",
      "out_encoder_ITZY Yuna.pkl\n",
      "out_encoder_ITZY Yeji.pkl\n",
      "[4, 3]\n"
     ]
    }
   ],
   "source": [
    "start_mosaic_function(imagefile, dont_want_mosaic_facelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "start_mosaic_function 지금은 통신에 대한 부분은 생각하지 않고 코드를 작성한다.\n",
    "\n",
    "중간에 통신으로 이미지를 받아오고 결과를 보내는 과정이 있으나, 지금은 생각하지 않고 진행한다.\n",
    "\n",
    "함수는 모자이크 처리를 원하는 want_mosaic_list를 받아 리스트에 해당하는 사람의 SVM_file, out_encoder을 검색해야한다.\n",
    "검색이 완료되면, 처리한 원하는 얼굴만 모자이크한 이미지를 return한다.\n",
    "\n",
    "'''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존에 작업했었던 코드\n",
    "\n",
    "def start_mosaic_function(filename, mosaic_facelist, SVM_file = \"SVM_Chaewon, Chaeyeon, Eunbi, Hitomi.sav\"):\n",
    "# filename는 이미지를 의미하고, mosaic_facelist는 모자이크를 하지 말아야하는 사람들 list를 의미한다.\n",
    "  face_list, coordinate_of_face_list = extract_face(filename, required_size=(160, 160))\n",
    "  \n",
    "  model = load_model('facenet_keras.h5')\n",
    "  face_embedding_list = get_embedding(model,face_list)\n",
    "  SVM_predict_result = svmPredict(face_embedding_list,SVM_file)\n",
    "\n",
    "  threshold = 90\n",
    "\n",
    "  for i, result in enumerate(SVM_predict_result):\n",
    "    #print(result[0], result[1])\n",
    "    if (result[0] in mosaic_facelist) and (result[1] >= threshold):\n",
    "      coordinate_of_face_list[i][4] = 1\n",
    "      #print(coordinate_of_face_list[i][4])\n",
    "  \n",
    "  image = Image.open(filename)\n",
    "  for [x1,y1,x2,y2,mosaic] in coordinate_of_face_list:\n",
    "    if mosaic == 0:\n",
    "      cropped_image = image.crop((x1,y1,x2,y2))\n",
    "      blurred_image = cropped_image.filter(ImageFilter.GaussianBlur(radius = 10))\n",
    "      image.paste(blurred_image,(x1,y1,x2,y2))\n",
    "  \n",
    "  image.show()\n",
    "  image.save('result_image3.jpg')\n",
    "  return image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
