{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "from numpy import load\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "from numpy import savez_compressed\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import mtcnn\n",
    "import numpy as np\n",
    "from numpy import save\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable for non-face-image\n",
    "nonface_array = np.zeros((160,160,3))\n",
    "\n",
    "# extract a single face from a given photograph\n",
    "# 학습하는 과정에선 하나의 이미지에는 학습 되고자 하는 한명의 얼굴이 1개만 있다고 가정하는게 프로젝트의 usecase에 맞아, 하나의 이미지에 얼굴이 여러개 있는 경우를 생각하지 않았다.\n",
    "def extract_face(filename, required_size=(160, 160)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = asarray(image)\n",
    "    # create the detector, using default weights\n",
    "    detector = MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    # extract the bounding box from the first face\n",
    "    try:\n",
    "        x1, y1, width, height = results[0]['box']\n",
    "        # bug fix\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        # extract the face\n",
    "        face = pixels[y1:y2, x1:x2]\n",
    "        # resize pixels to the model size\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "        face_array = asarray(image)\n",
    "    except:\n",
    "        print(filename + \" this image doesn't have face\")\n",
    "        return  np.zeros((160,160,3)) \n",
    "    #얼굴이 검출이 안될경우를 대비하여 None을 return한다.\n",
    "    return face_array\n",
    " \n",
    "# load images and extract faces for all images in a directory\n",
    "def load_faces(directory):\n",
    "    faces = list()\n",
    "    # enumerate files\n",
    "    for filename in listdir(directory):\n",
    "        # path\n",
    "        path = directory + filename\n",
    "        # get face\n",
    "        face = extract_face(path)\n",
    "        \n",
    "        if (face == nonface_array).all():\n",
    "            continue    \n",
    "        else:\n",
    "            faces.append(face)\n",
    "    return faces\n",
    " \n",
    "# load a dataset that contains one subdir for each class that in turn contains images\n",
    "def load_dataset(directory):\n",
    "    X = list()\n",
    "    y = list()\n",
    "    \n",
    "    subdir_list = list()\n",
    "    \n",
    "    # enumerate folders, on per class\n",
    "    for subdir in listdir(directory):        \n",
    "        subdir_list.append(subdir)\n",
    "        \n",
    "        # path\n",
    "        path = directory + subdir + '/'\n",
    "        # skip any files that might be in the dir\n",
    "        if not isdir(path):\n",
    "            continue\n",
    "        # load all faces in the subdirectory\n",
    "        faces = load_faces(path)\n",
    "        # create labels\n",
    "        labels = [subdir for _ in range(len(faces))]\n",
    "        # summarize progress\n",
    "        print('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
    "        # store\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "\n",
    "    return asarray(X), asarray(y), subdir_list, y\n",
    " \n",
    "# get the face embedding for one face\n",
    "def get_embedding(model, face_pixels):\n",
    "    # scale pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    # standardize pixel values across channels (global)\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    # transform face into one sample\n",
    "    samples = expand_dims(face_pixels, axis=0)\n",
    "    # make prediction to get embedding\n",
    "    yhat = model.predict(samples)\n",
    "    \n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_embedding된 것이 하나도 없고, 처음으로 학습을 진행하는 경우로, 이미지 100개를 가진 폴더가 몇개 존재하며 폴더의 이름은 y값으로 될 것이다.\n",
    "def trainY_and_embedding():\n",
    "    model_path = \"facenet_keras_weight_module/facenet_keras.h5\"\n",
    "    image_folder_path = 'image/'\n",
    "    \n",
    "    trainX, trainY, subdir_list, y= load_dataset(image_folder_path)\n",
    "    \n",
    "    save('trainY',trainY)\n",
    "    \n",
    "    # print(trainX.shape, trainY.shape)\n",
    "    newtrainX = list()\n",
    "    \n",
    "    # load the facenet model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    for face_pixels in trainX:\n",
    "        embedding = get_embedding(model, face_pixels)\n",
    "        newtrainX.append(embedding)\n",
    "    \n",
    "    save('face_embedding/face_embedding', newtrainX)\n",
    "    \n",
    "    print(len(newtrainY))\n",
    "    \n",
    "    subdir_index_list = list()\n",
    "    \n",
    "    others_list = ['others' for _ in range(len(trainY))]\n",
    "   \n",
    "    # trainY의 구분점을 찾기위한 과정 + trainY에서 others 변수 만드는 과정\n",
    "    mod = sys.modules[__name__]\n",
    "    \n",
    "    for subdir in subdir_list:\n",
    "        subdir_index_list.append(y.index(subdir))\n",
    "    \n",
    "    for i, subdir in enumerate(subdir_list):\n",
    "        if i == len(subdir_index_list ) - 1: #subdir_index_list의 마지막 index일 경우, range(subdir_index_list[i] : len(trainT))\n",
    "                for index in range(subdir_index_list[i], len(trainY)):\n",
    "                    others_list[index] = subdir\n",
    "                    \n",
    "                save('trainY/trainY_{}'.format(subdir),asarray(others_list))\n",
    "                \n",
    "                others_list = ['others' for _ in range(len(trainY))]\n",
    "\n",
    "        else: \n",
    "            for index in range(subdir_index_list[i], subdir_index_list[i + 1]):\n",
    "                others_list[index] = subdir     \n",
    "                \n",
    "            save('trainY/trainY_{}'.format(subdir),asarray(others_list))\n",
    "            others_list = ['others' for _ in range(len(trainY))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVM_and_encoder():\n",
    "    embedding_path = 'face_embedding/face_embedding.npy'\n",
    "    trainY_path = 'trainY/'\n",
    "    \n",
    "    # normalize input vectors\n",
    "    trainX = load(embedding_path)\n",
    "    in_encoder = Normalizer(norm = 'l2')\n",
    "    trainX = in_encoder.transform(trainX)\n",
    "    \n",
    "    #label encode targets\n",
    "    out_encoder = LabelEncoder()\n",
    "    \n",
    "    trainY_list = listdir(trainY_path)\n",
    "    \n",
    "    for trainY_dir in trainY_list:\n",
    "        \n",
    "        trainY = load(trainY_path + trainY_dir)\n",
    "        out_encoder.fit(trainY)\n",
    "        \n",
    "        trainY_dir = trainY_dir.replace(\"trainY_\",\"\")\n",
    "        trainY_dir = trainY_dir.replace(\".npy\",\"\")\n",
    "        \n",
    "        if os.path.isfile(\"out_encoder/out_encoder_{}.pkl\".format(trainY_dir)):\n",
    "            os.remove(\"out_encoder/out_encoder_{}.pkl\".format(trainY_dir))\n",
    "            \n",
    "        pickle.dump(out_encoder,open(\"out_encoder/out_encoder_{}.pkl\".format(trainY_dir),'wb'))\n",
    "        trainY = out_encoder.transform(trainY)\n",
    "        \n",
    "        # fit model\n",
    "        model = SVC(kernel = 'linear', probability = True)\n",
    "        model.fit(trainX,trainY)\n",
    "        \n",
    "        if os.path.isfile(\"SVM/SVM_others_{}.pkl\".format(trainY_dir)):\n",
    "            os.remove(\"SVM/SVM_others_{}.pkl\".format(trainY_dir))\n",
    "            \n",
    "        pickle.dump(model,open(\"SVM/SVM_{}.pkl\".format(trainY_dir),'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_train():\n",
    "    trainY_and_embedding()\n",
    "    train_SVM_and_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded 119 examples for class: ITZY Lia\n",
      ">loaded 103 examples for class: ioi Sejeong\n",
      ">loaded 10 examples for class: izone Minju\n",
      "image/redvelvet Joy/redvelvet_Joy (32).jpg this image doesn't have face\n",
      ">loaded 138 examples for class: redvelvet Joy\n",
      ">loaded 89 examples for class: ioi Yeonjung\n",
      ">loaded 138 examples for class: twice Tzuyu\n",
      ">loaded 122 examples for class: ioi Chaeyeon\n",
      ">loaded 146 examples for class: exid Hyelin\n",
      ">loaded 10 examples for class: izone Eunbi\n",
      ">loaded 128 examples for class: ioi Chungha\n",
      ">loaded 128 examples for class: mamamoo Hwasa\n",
      ">loaded 124 examples for class: twice Jeongyeon\n",
      "image/redvelvet Wendy/redvelvet_Wendy (2).jpg this image doesn't have face\n",
      ">loaded 118 examples for class: redvelvet Wendy\n",
      ">loaded 112 examples for class: ioi Kyulkyung\n",
      ">loaded 10 examples for class: izone Hyewon\n",
      ">loaded 113 examples for class: ITZY Chaeryeong\n",
      "image/izone Yujin/izone_Yujin (40).jpg this image doesn't have face\n",
      ">loaded 143 examples for class: izone Yujin\n",
      ">loaded 111 examples for class: mamamoo Solar\n",
      ">loaded 123 examples for class: redvelvet Seulgi\n",
      ">loaded 10 examples for class: izone Sakura\n",
      "image/ioi Yoojung/ioi_Yoojung (84).jpg this image doesn't have face\n",
      "image/ioi Yoojung/ioi_Yoojung (47).jpg this image doesn't have face\n",
      ">loaded 105 examples for class: ioi Yoojung\n",
      ">loaded 137 examples for class: ITZY Yuna\n",
      "image/mamamoo Wheein/mamamoo_Wheein (52).jpg this image doesn't have face\n",
      ">loaded 121 examples for class: mamamoo Wheein\n",
      ">loaded 130 examples for class: twice Mina\n",
      ">loaded 134 examples for class: ITZY Ryujin\n",
      ">loaded 116 examples for class: izone Yena\n",
      ">loaded 128 examples for class: twice Momo\n",
      ">loaded 139 examples for class: redvelvet Yeri\n"
     ]
    }
   ],
   "source": [
    "first_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "143px",
    "left": "1088px",
    "right": "20px",
    "top": "108px",
    "width": "759px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
