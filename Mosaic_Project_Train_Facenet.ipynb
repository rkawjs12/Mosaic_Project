{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "from numpy import load\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "from numpy import savez_compressed\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import mtcnn\n",
    "import numpy as np\n",
    "from numpy import save\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable for non-face-image\n",
    "nonface_array = np.zeros((160,160,3))\n",
    "\n",
    "# extract a single face from a given photograph\n",
    "# 학습하는 과정에선 하나의 이미지에는 학습 되고자 하는 한명의 얼굴이 1개만 있다고 가정하는게 프로젝트의 usecase에 맞아, 하나의 이미지에 얼굴이 여러개 있는 경우를 생각하지 않았다.\n",
    "def extract_face(filename, required_size=(160, 160)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = asarray(image)\n",
    "    # create the detector, using default weights\n",
    "    detector = MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    # extract the bounding box from the first face\n",
    "    try:\n",
    "        x1, y1, width, height = results[0]['box']\n",
    "        # bug fix\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        # extract the face\n",
    "        face = pixels[y1:y2, x1:x2]\n",
    "        # resize pixels to the model size\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "        face_array = asarray(image)\n",
    "    except:\n",
    "        print(filename + \" this image doesn't have face\")\n",
    "        return  np.zeros((160,160,3)) \n",
    "    #얼굴이 검출이 안될경우를 대비하여 None을 return한다.\n",
    "    return face_array\n",
    " \n",
    "# load images and extract faces for all images in a directory\n",
    "def load_faces(directory):\n",
    "    faces = list()\n",
    "    # enumerate files\n",
    "    for filename in listdir(directory):\n",
    "        # path\n",
    "        path = directory + filename\n",
    "        # get face\n",
    "        face = extract_face(path)\n",
    "        \n",
    "        if (face == nonface_array).all():\n",
    "            continue    \n",
    "        else:\n",
    "            faces.append(face)\n",
    "    return faces\n",
    " \n",
    "# load a dataset that contains one subdir for each class that in turn contains images\n",
    "def load_dataset(directory):\n",
    "    X = list()\n",
    "    y = list()\n",
    "    \n",
    "    subdir_list = list()\n",
    "    \n",
    "    # enumerate folders, on per class\n",
    "    for subdir in listdir(directory):        \n",
    "        subdir_list.append(subdir)\n",
    "        \n",
    "        # path\n",
    "        path = directory + subdir + '/'\n",
    "        # skip any files that might be in the dir\n",
    "        if not isdir(path):\n",
    "            continue\n",
    "        # load all faces in the subdirectory\n",
    "        faces = load_faces(path)\n",
    "        # create labels\n",
    "        labels = [subdir for _ in range(len(faces))]\n",
    "        # summarize progress\n",
    "        print('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
    "        # store\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "\n",
    "    return asarray(X), asarray(y), subdir_list, y\n",
    " \n",
    "# get the face embedding for one face\n",
    "def get_embedding(model, face_pixels):\n",
    "    # scale pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    # standardize pixel values across channels (global)\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    # transform face into one sample\n",
    "    samples = expand_dims(face_pixels, axis=0)\n",
    "    # make prediction to get embedding\n",
    "    yhat = model.predict(samples)\n",
    "    \n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_embedding된 것이 하나도 없고, 처음으로 학습을 진행하는 경우로, 이미지 100개를 가진 폴더가 몇개 존재하며 폴더의 이름은 y값으로 될 것이다.\n",
    "def trainY_and_embedding():\n",
    "    model_path = \"facenet_keras_weight_module/facenet_keras.h5\"\n",
    "    image_folder_path = 'image_for_test/'\n",
    "    \n",
    "    trainX, trainY, subdir_list, y= load_dataset(image_folder_path)\n",
    "    \n",
    "    save('trainY',trainY)\n",
    "    \n",
    "    # print(trainX.shape, trainY.shape)\n",
    "    newtrainX = list()\n",
    "    \n",
    "    # load the facenet model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    for face_pixels in trainX:\n",
    "        embedding = get_embedding(model, face_pixels)\n",
    "        newtrainX.append(embedding)\n",
    "    \n",
    "    save('face_embedding/face_embedding', newtrainX)\n",
    "    subdir_index_list = list()\n",
    "    \n",
    "    others_list = ['others' for _ in range(len(trainY))]\n",
    "   \n",
    "    # trainY의 구분점을 찾기위한 과정 + trainY에서 others 변수 만드는 과정\n",
    "    mod = sys.modules[__name__]\n",
    "    \n",
    "    for subdir in subdir_list:\n",
    "        subdir_index_list.append(y.index(subdir))\n",
    "    \n",
    "    for i, subdir in enumerate(subdir_list):\n",
    "        if i == len(subdir_index_list ) - 1: #subdir_index_list의 마지막 index일 경우, range(subdir_index_list[i] : len(trainT))\n",
    "                for index in range(subdir_index_list[i], len(trainY)):\n",
    "                    others_list[i] = subdir\n",
    "                    \n",
    "                save('trainY/trainY_{}'.format(subdir),asarray(others_list))\n",
    "                others_list = ['others' for _ in range(len(trainY))]\n",
    "\n",
    "        else: \n",
    " \n",
    "            for index in range(subdir_index_list[i], subdir_index_list[i + 1]):\n",
    "                others_list[i] = subdir\n",
    "                \n",
    "            save('trainY/trainY_{}'.format(subdir),asarray(others_list))\n",
    "            others_list = ['others' for _ in range(len(trainY))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVM_and_encoder():\n",
    "    embedding_path = 'face_embedding/face_embedding.npy'\n",
    "    trainY_path = 'trainY/'\n",
    "    \n",
    "    # normalize input vectors\n",
    "    trainX = load(embedding_path)\n",
    "    in_encoder = Normalizer(norm = 'l2')\n",
    "    trainX = in_encoder.transform(trainX)\n",
    "    \n",
    "    #label encode targets\n",
    "    out_encoder = LabelEncoder()\n",
    "    \n",
    "    trainY_list = listdir(trainY_path)\n",
    "    \n",
    "    for trainY_dir in trainY_list:\n",
    "        \n",
    "        trainY = load(trainY_path + trainY_dir)\n",
    "        out_encoder.fit(trainY)\n",
    "        \n",
    "        trainY_dir = trainY_dir.replace(\"trainY_\",\"\")\n",
    "        trainY_dir = trainY_dir.replace(\".npy\",\"\")\n",
    "        \n",
    "        print(trainY_dir)\n",
    "        \n",
    "        if os.path.isfile(\"out_encoder/out_encoder_{}.pkl\".format(trainY_dir)):\n",
    "            os.remove(\"out_encoder/out_encoder_{}.pkl\".format(trainY_dir))\n",
    "            \n",
    "        pickle.dump(out_encoder,open(\"out_encoder/out_encoder_{}.pkl\".format(trainY_dir),'wb'))\n",
    "        trainY = out_encoder.transform(trainY)\n",
    "        \n",
    "        # fit model\n",
    "        model = SVC(kernel = 'linear', probability = True)\n",
    "        model.fit(trainX,trainY)\n",
    "        \n",
    "        if os.path.isfile(\"SVM/SVM_others_{}.pkl\".format(trainY_dir)):\n",
    "            os.remove(\"SVM/SVM_others_{}.pkl\".format(trainY_dir))\n",
    "            \n",
    "        pickle.dump(model,open(\"SVM/SVM_{}.pkl\".format(trainY_dir),'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_train():\n",
    "    trainY_and_embedding()\n",
    "    train_SVM_and_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded 1 examples for class: ITZY Chaeryeong\n",
      ">loaded 4 examples for class: ITZY Lia\n",
      ">loaded 4 examples for class: ITZY Yuna\n",
      "image_for_test/ITZY Yeji/ITZY_Yeji (54).jpg this image doesn't have face\n",
      ">loaded 5 examples for class: ITZY Yeji\n",
      ">loaded 5 examples for class: ITZY Ryujin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yooseungwoo/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITZY Yuna\n",
      "ITZY Chaeryeong\n",
      "ITZY Ryujin\n",
      "ITZY Yeji\n",
      "ITZY Lia\n"
     ]
    }
   ],
   "source": [
    "first_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "143px",
    "left": "1088px",
    "right": "20px",
    "top": "108px",
    "width": "759px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
